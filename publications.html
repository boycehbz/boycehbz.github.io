---
layout: page
title: Publications
---

<div width="100%" style="vertical-align: top;" align="center" style="width:15vmin;height:80px" class="side-side-side">
    <div align="left"; class="toleft"; width="30%">
        <img style="max-height: 200px; max-width: 200px;" width="100%" class="image" src="HBZ-Pose2UV-2022-06.jpg" >
    </div>
    <div align="left"; style="vertical-align: top;" class="toright"; width="60%"; word-break:break-all;word-wrap:break-word;>
        <span style="display:inline-block;font-size:1.9rem;font-weight:bold;padding-bottom:1.0rem">Pose2UV: Single-shot Multi-person Mesh Recovery with Deep UV Prior</span>
        <!-- <span style="display:inline-block;font-size:1.5rem;color:#FF1A1A;font-weight:bold;"> (Oral Presentation)</span> -->
        <span style="display:block;font-size:1.5rem;font-family:Arial;padding-bottom:0.1rem"><i> IEEE Transactions on Image Processing (<strong>TIP</strong>), 2022</i></span>
        <span style="display:block;font-size:1.5rem;font-family:Arial;padding-bottom:0.7rem"><b>Buzhen Huang</b>, Tianshu Zhang and Yangang Wang</span>
        <!-- <span style="display:inline-block;font-size:1.3rem;font-family:Arial;padding-bottom:0.1rem">(*equal contribution)</span> -->
        <span style="display:inline-block;font-size:1.3rem;font-family:Arial;"><a href="https://www.yangangwang.com/papers/HBZ-Pose2UV-2022-06.html" target="_blank">[website]</a></span>
        <span style="display:inline-block;font-size:1.3rem;font-family:Arial;"><a href="https://www.yangangwang.com/papers/HBZ-pose2uv-2022-06.pdf" target="_blank">[paper]</a></span> <span style="display:inline-block;font-size:1.3rem;font-family:Arial;"><a href="https://www.bilibili.com/video/BV19t4y1h7vJ" target="_blank">[video]</a></span>
        <!-- <span style="display:inline-block;font-size:1.3rem;font-family:Arial;"><a href="" target="_blank">[sup.mat.]</a></span>  -->
    </div>
</div>
<hr style="margin-top:-40px;margin-bottom:-40px;height:0.1em;width:100%;font-size:0.1em;line-height:0.2em;border-top:1px solid #dedddd;"/>

<div width="100%" style="vertical-align: top;" align="center" style="width:15vmin;height:80px" class="side-side-side">
    <div align="left"; class="toleft"; width="30%">
        <img style="max-height: 200px; max-width: 200px;" width="100%" class="image" src="HBZ-NM-2022-03.jpg" >
    </div>
    <div align="left"; style="vertical-align: top;" class="toright"; width="60%"; word-break:break-all;word-wrap:break-word;>
        <span style="display:inline-block;font-size:1.9rem;font-weight:bold;padding-bottom:1.0rem">Neural MoCon: Neural Motion Control for Physically Plausible Human Motion Capture</span>
        <!-- <span style="display:inline-block;font-size:1.5rem;color:#FF1A1A;font-weight:bold;"> (Oral Presentation)</span> -->
        <span style="display:block;font-size:1.5rem;font-family:Arial;padding-bottom:0.1rem"><i> IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2022</i></span>
        <span style="display:block;font-size:1.5rem;font-family:Arial;padding-bottom:0.7rem"><b>Buzhen Huang</b>, Liang Pan, Yuan Yang, Jingyi Ju and Yangang Wang</span>
        <!-- <span style="display:inline-block;font-size:1.3rem;font-family:Arial;padding-bottom:0.1rem">(*contribute equally)</span> -->
        <span style="display:inline-block;font-size:1.3rem;font-family:Arial;"><a href="https://www.yangangwang.com/papers/HBZ-NM-2022-03.html" target="_blank">[website]</a></span>
        <span style="display:inline-block;font-size:1.3rem;font-family:Arial;"><a href="https://www.yangangwang.com/papers/HBZ-NM-2022-03.pdf" target="_blank">[paper]</a></span> <span style="display:inline-block;font-size:1.3rem;font-family:Arial;"><a href="https://www.bilibili.com/video/BV1W94y1f7ht" target="_blank">[video]</a></span> <span style="display:inline-block;font-size:1.3rem;font-family:Arial;"><a href="https://www.bilibili.com/video/BV1pR4y1P7nJ?spm_id_from=333.337.search-card.all.click" target="_blank">[talk]</a></span>
        <!-- <span style="display:inline-block;font-size:1.3rem;font-family:Arial;"><a href="" target="_blank">[sup.mat.]</a></span>  -->
    </div>
</div>
<hr style="margin-top:-40px;margin-bottom:-40px;height:0.1em;width:100%;font-size:0.1em;line-height:0.2em;border-top:1px solid #dedddd;"/>

<div width="100%" style="vertical-align: top;" align="center" style="width:15vmin;height:80px" class="side-side-side">
    <div align="left"; class="toleft"; width="30%">
        <img style="max-height: 200px; max-width: 200px;" width="100%" class="image" src="HUANG-3DV-2021-10-teaser.jpg" >
    </div>
    <div align="left"; style="vertical-align: top;" class="toright"; width="60%"; word-break:break-all;word-wrap:break-word;>
        <span style="display:inline-block;font-size:1.9rem;font-weight:bold;padding-bottom:1.5rem">Dynamic Multi-Person Mesh Recovery from Uncalibrated Multi-View Cameras</span>
        <!-- <span style="display:inline-block;font-size:1.5rem;color:#FF1A1A;font-weight:bold;"> (Oral Presentation)</span> -->
        <span style="display:block;font-size:1.5rem;font-family:Arial;padding-bottom:0.1rem"><i> International Conference on 3D Vision (<strong>3DV</strong>), 2021</i></span>
        <span style="display:block;font-size:1.5rem;font-family:Arial;padding-bottom:1.1rem"><b>Buzhen Huang</b>, Yuan Shu, Tianshu Zhang and Yangang Wang</span>
        <!-- <span style="display:inline-block;font-size:1.3rem;font-family:Arial;padding-bottom:0.1rem">(*contribute equally)</span> -->
        <span style="display:inline-block;font-size:1.3rem;font-family:Arial;"><a href="https://arxiv.org/pdf/2110.10355.pdf" target="_blank">[paper]</a></span> <span style="display:inline-block;font-size:1.3rem;font-family:Arial;"><a href="https://github.com/boycehbz/DMMR" target="_blank">[code]</a></span> <span style="display:inline-block;font-size:1.3rem;font-family:Arial;"><a href="https://www.bilibili.com/video/BV1Qq4y1d78S" target="_blank">[video]</a></span>
        <span style="display:inline-block;font-size:1.3rem;font-family:Arial;"><a href="papers/3DV2021-SupplementaryMaterial.pdf" target="_blank">[sup.mat.]</a></span> 
    </div>
</div>
<hr style="margin-top:-40px;height:0.1em;width:100%;font-size:0.1em;line-height:0.2em;border-top:1px solid #dedddd;"/>

<div width="100%" style="vertical-align: top;margin-top: -20px" align="center" style="width:15vmin;height:80px" class="side-side-side">
    <div align="left"; class="toleft"; width="30%">
        <img style="max-height: 200px; max-width: 200px;" width="100%" class="image" src="occlusion_teaser.jpg" >
    </div>
    <div align="left"; style="vertical-align: top;" class="toright"; width="60%"; word-break:break-all;word-wrap:break-word;>
        <span style="display:inline-block;font-size:1.9rem;font-weight:bold;">Object-Occluded Human Shape and Pose Estimation from a Single Color Image</span>
        <span style="display:inline-block;font-size:1.5rem;color:#FF1A1A;font-weight:bold;"> (Oral Presentation)</span>
        <span style="display:block;font-size:1.5rem;font-family:Arial;padding-bottom:0.1rem"><i> IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2020</i></span>
        <span style="display:block;font-size:1.5rem;font-family:Arial;padding-bottom:0.1rem">Tianshu Zhang*, <b>Buzhen Huang*</b>, Yangang Wang</span>
        <span style="display:inline-block;font-size:1.3rem;font-family:Arial;padding-bottom:0.1rem">(*equal contribution)</span>
        <span style="display:inline-block;font-size:1.3rem;font-family:Arial;"><a href="https://www.yangangwang.com/papers/ZHANG-OOH-2020-03.html" target="_blank">[website]</a></span>
        <span style="display:inline-block;font-size:1.3rem;font-family:Arial;"><a href="https://www.yangangwang.com/papers/ZHANG-OOH-2020-03.pdf" target="_blank">[paper]</a></span> <span style="display:inline-block;font-size:1.3rem;font-family:Arial;"><a href="https://gitee.com/seuvcl/CVPR2020-OOH" target="_blank">[code]</a></span> <span style="display:inline-block;font-size:1.3rem;font-family:Arial;"><a href="https://www.youtube.com/watch?v=8udm2OB0A-U&t=72s" target="_blank">[video]</a></span>
    </div>
</div>
<hr style="margin-top:-40px;height:0.1em;width:100%;font-size:0.1em;line-height:0.2em;border-top:1px solid #dedddd;"/>

<div width="100%" style="vertical-align: top;margin-top: -20px" align="center" style="width:15vmin;height:80px" class="side-side-side">
    <div align="left" class="toleft" width="30%">
        <img style="max-height: 200px; max-width: 200px;" width="100%" class="image" src="flower.jpg" >
    </div>
    <div align="left" style="vertical-align: top;" class="toright"; width="60%"; word-break:break-all;word-wrap:break-word;>
        <span style="display:inline-block;font-size:1.9rem;font-weight:bold;padding-bottom:1.5rem">A Flower Classification Framework Based on Ensemble of CNNs</span>
        <span style="display:inline-block;font-size:1.5rem;font-family:Arial;padding-bottom:0.1rem"><i> 19th Pacific-Rim Conference on Multimedia (PCM), 2018</i></span>
        <span style="display:inline-block;font-size:1.5rem;font-family:Arial;padding-bottom:0.1rem"><b>Buzhen Huang</b>, Youpeng Hu, Yaoqi Sun, Xinhong Hao, Chenggang Yan</span>

    </div>
</div>
<hr style="margin-top:-40px;height:0.1em;width:100%;font-size:0.1em;line-height:0.2em;border-top:1px solid #dedddd;"/>

